import os
import glob
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from PIL import ImageFile
ImageFile.MAXBLOCK = 1024 * 1024

def read_and_convert_images(input_dir, output_dir, target_format='PNG', target_mode='RGB', target_size=None):
    """
    è¯»å– input_dir å†…æ‰€æœ‰ JPG å›¾åƒï¼Œè½¬æ¢é¢œè‰²æ¨¡å¼å’Œå°ºå¯¸ï¼Œå¹¶ä¿å­˜ä¸º target_format æ ¼å¼ã€‚
    å¦‚æœæ–‡ä»¶å·²ç»è½¬æ¢ï¼Œåˆ™è·³è¿‡ã€‚
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # è·å–æ‰€æœ‰ JPG æ–‡ä»¶è·¯å¾„
    image_paths = glob.glob(os.path.join(input_dir, '*.jpg'))
    print(f"å…±æ‰¾åˆ° {len(image_paths)} å¼  JPG å›¾åƒï¼Œå¼€å§‹æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢...")

    processed_paths = []
    skipped_count = 0

    for img_path in image_paths:
        try:
            base_name = os.path.basename(img_path)
            name, _ = os.path.splitext(base_name)
            out_path = os.path.join(output_dir, name + '.' + target_format.lower())

            # **æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨è½¬æ¢åçš„æ–‡ä»¶**
            if os.path.exists(out_path):
                print(f"âœ… å·²è½¬æ¢ï¼Œè·³è¿‡: {out_path}")
                skipped_count += 1
                processed_paths.append(out_path)
                continue  # ç›´æ¥è·³è¿‡å½“å‰å¾ªç¯

            with Image.open(img_path) as img:
                # è½¬æ¢é¢œè‰²æ¨¡å¼
                if img.mode != target_mode:
                    img = img.convert(target_mode)
                # è°ƒæ•´å°ºå¯¸ï¼ˆå¦‚æœè®¾ç½®ï¼‰
                if target_size:
                    img = img.resize(target_size, Image.ANTIALIAS)

                # ä¿å­˜æ–°æ ¼å¼çš„å›¾åƒ
                img.save(out_path, target_format)
                processed_paths.append(out_path)
                print(f"âœ… å¤„ç†å®Œæˆ: {out_path}")

        except Exception as e:
            print(f"âŒ å¤„ç† {img_path} æ—¶å‡ºé”™ï¼š{e}")

    print(f"ğŸ¯ å¤„ç†å®Œæˆï¼Œæ€»å…± {len(processed_paths)} å¼ å›¾ç‰‡ï¼Œå…¶ä¸­ {skipped_count} å¼ å·²å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
    return processed_paths

def apply_clahe(image):
    """
    å¯¹è¾“å…¥çš„å½©è‰²å›¾åƒåº”ç”¨ CLAHE å‡è¡¡åŒ–ï¼Œå…ˆè½¬æ¢åˆ° LAB é¢œè‰²ç©ºé—´ï¼Œåªå¤„ç†äº®åº¦é€šé“ã€‚
    """
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l_eq = clahe.apply(l)
    lab_eq = cv2.merge((l_eq, a, b))
    image_eq = cv2.cvtColor(lab_eq, cv2.COLOR_LAB2BGR)
    return image_eq


def denoise_image(image):
    """
    å¯¹å›¾åƒè¿›è¡Œå™ªå£°å»é™¤ï¼Œé‡‡ç”¨é«˜æ–¯æ¨¡ç³Šå¤„ç†ã€‚
    """
    return cv2.GaussianBlur(image, (5, 5), 0)


def enhance_image(image):
    """
    å¯¹å›¾åƒè¿›è¡Œç®€å•çš„é”åŒ–å¢å¼ºå¤„ç†ã€‚
    """
    kernel = np.array([[0, -1, 0],
                       [-1, 5, -1],
                       [0, -1, 0]])
    enhanced = cv2.filter2D(image, -1, kernel)
    return enhanced


def process_image_pipeline(input_img_path, output_path):
    """
    å¯¹å•å¼ å›¾åƒè¿›è¡Œæ•´ä½“é¢„å¤„ç†ï¼šè¯»å–ã€CLAHE äº®åº¦å‡è¡¡ã€å™ªå£°å»é™¤ã€å›¾åƒå¢å¼ºåä¿å­˜ã€‚
    å¦‚æœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡å¤„ç†ã€‚
    """
    # å¦‚æœå¤„ç†åçš„æ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è·³è¿‡
    if os.path.exists(output_path):
        print(f"å¤„ç†åçš„å›¾åƒ {output_path} å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†ã€‚")
        return

    # è¯»å–å›¾åƒï¼ˆä½¿ç”¨ OpenCV è¯»å–ï¼Œæ ¼å¼ä¸º BGRï¼‰
    img = cv2.imread(input_img_path)
    if img is None:
        print(f"æ— æ³•è¯»å–å›¾åƒ {input_img_path}")
        return

    # äº®åº¦å‡è¡¡ï¼ˆCLAHEï¼‰
    img_eq = apply_clahe(img)
    # å™ªå£°å»é™¤





    img_denoised = denoise_image(img_eq)
    # å›¾åƒå¢å¼ºï¼ˆé”åŒ–ï¼‰
    img_enhanced = enhance_image(img_denoised)

    # ä¿å­˜å¤„ç†ç»“æœï¼ˆä¿å­˜ä¸º PNG æ ¼å¼ï¼‰
    cv2.imwrite(output_path, img_enhanced)
    processed_img = cv2.imread(output_path)
    if processed_img is not None:
        print(f"å¤„ç†åå°ºå¯¸: {processed_img.shape}")
    print(f"ä¿å­˜å¤„ç†åçš„å›¾åƒï¼š{output_path}")



def batch_process_images(input_dir, output_dir):
    """
    å¯¹ input_dir ä¸­æ‰€æœ‰å›¾åƒæ‰¹é‡æ‰§è¡Œé¢„å¤„ç†ï¼Œå¹¶ä¿å­˜åˆ° output_dirã€‚
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # å‡è®¾å›¾ç‰‡å·²ç»é¢„å…ˆè½¬æ¢æ ¼å¼ï¼ˆä¹Ÿå¯ä»¥ç›´æ¥åœ¨æ­¤å¤„å¤„ç†ï¼‰
    image_paths = glob.glob(os.path.join(input_dir, '*.png'))
    for img_path in image_paths:
        base_name = os.path.basename(img_path)
        name, _ = os.path.splitext(base_name)
        out_path = os.path.join(output_dir, name + '.png')
        process_image_pipeline(img_path, out_path)


def pad_to_same_height(img1, img2):
    """
    ä¸ç¼©æ”¾ï¼Œåªå¯¹é«˜åº¦è¾ƒå°çš„å›¾åƒè¿›è¡Œä¸Šä¸‹é»‘è¾¹å¡«å……ï¼Œ
    ä½¿å¾—ä¸¤å¼ å›¾åƒçš„é«˜åº¦ç›¸åŒã€‚
    """
    h1, w1 = img1.shape[:2]
    h2, w2 = img2.shape[:2]

    # ä»¥æ›´å¤§çš„é«˜åº¦ä½œä¸ºç›®æ ‡
    target_height = max(h1, h2)

    # å¡«å……ç¬¬1å¼ å›¾åƒ
    if h1 < target_height:
        # éœ€è¦å¡«å……å¤šå°‘åƒç´ 
        pad_total = target_height - h1
        # ä¹Ÿå¯ä»¥åªå¡«åœ¨ä¸‹æ–¹ï¼Œè¿™é‡Œç¤ºä¾‹å¹³å‡å¡«å……åˆ°ä¸Šä¸‹
        top_pad = pad_total // 2
        bottom_pad = pad_total - top_pad
        img1 = cv2.copyMakeBorder(img1, top_pad, bottom_pad, 0, 0,
                                  borderType=cv2.BORDER_CONSTANT,
                                  value=(0, 0, 0))

    # å¡«å……ç¬¬2å¼ å›¾åƒ
    if h2 < target_height:
        pad_total = target_height - h2
        top_pad = pad_total // 2
        bottom_pad = pad_total - top_pad
        img2 = cv2.copyMakeBorder(img2, top_pad, bottom_pad, 0, 0,
                                  borderType=cv2.BORDER_CONSTANT,
                                  value=(0, 0, 0))

    return img1, img2


def pair_images_and_concat(image_list, output_dir, concat_axis=1):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    paired = [image_list[i:i + 2] for i in range(0, len(image_list), 2)]
    for i, pair in enumerate(paired):
        if len(pair) == 2:
            img1 = cv2.imread(pair[0])
            img2 = cv2.imread(pair[1])
            print(f"æ‹¼æ¥å‰å°ºå¯¸: {pair[0]} -> {img1.shape}, {pair[1]} -> {img2.shape}")

            # ç”¨å¡«å……æ–¹å¼ç»Ÿä¸€é«˜åº¦
            img1_padded, img2_padded = pad_to_same_height(img1, img2)
            print(f"å¡«å……åå°ºå¯¸: {pair[0]} -> {img1_padded.shape}, {pair[1]} -> {img2_padded.shape}")

            concatenated = np.concatenate((img1_padded, img2_padded), axis=concat_axis)

            # æ ¹æ®å·¦å›¾çš„æ–‡ä»¶åæå–æ•°å­—éƒ¨åˆ†ä½œä¸ºè¾“å‡ºåç§°
            base_name = os.path.basename(pair[0])
            name, ext = os.path.splitext(base_name)
            tokens = name.split('_')
            if tokens:
                common_num = tokens[0]
            else:
                common_num = name

            out_path = os.path.join(output_dir, f"{common_num}.png")
            cv2.imwrite(out_path, concatenated)
            print(f"ä¿å­˜æ‹¼æ¥å›¾åƒï¼š{out_path}")
        else:
            print(f"æœ€åä¸€ç»„å›¾åƒä¸è¶³ä¸¤å¼ ï¼Œè·³è¿‡ã€‚")

if __name__ == '__main__':
    # ä½¿ç”¨å®é™…è·¯å¾„ï¼Œä¸è¦ç”¨ "path/to/your/input_folder"
    input_dir = r"D:\competition\Training_Dataset"  # å­˜æ”¾åŸå§‹4000å¼  jpg å›¾åƒçš„æ–‡ä»¶å¤¹è·¯å¾„
    preprocessed_dir = r"D:\competition\preprocessed_dir"  # é¢„å¤„ç†åï¼ˆæ ¼å¼è½¬æ¢ï¼‰çš„è¾“å‡ºæ–‡ä»¶å¤¹
    processed_dir = r"D:\competition\processed_dir"  # é¢„å¤„ç†åå›¾åƒï¼ˆCLAHEã€é™å™ªã€å¢å¼ºï¼‰çš„è¾“å‡ºæ–‡ä»¶å¤¹
    paired_dir = r"D:\competition\paired_dir"  # æ‹¼æ¥åçš„å›¾åƒä¿å­˜è·¯å¾„

    # å°†æ‰€æœ‰å›¾åƒè½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼ï¼ˆä¾‹å¦‚è½¬æ¢é¢œè‰²æ¨¡å¼å’Œå°ºå¯¸ï¼Œå¯é€‰ï¼‰
    _ = read_and_convert_images(input_dir, preprocessed_dir, target_format='PNG', target_mode='RGB', target_size=None)

    # 2. å¯¹æ¯å¼ å›¾åƒè¿›è¡Œäº®åº¦å‡è¡¡ã€å™ªå£°å»é™¤å’Œå¢å¼ºå¤„ç†

    batch_process_images(preprocessed_dir, processed_dir)

    # 3. å¦‚æœæ˜¯åŒç›®å›¾åƒï¼Œéœ€è¦å°†å¤„ç†åçš„å›¾åƒä¸¤ä¸¤æ‹¼æ¥
    processed_images = sorted(glob.glob(os.path.join(processed_dir, '*.png')))
    if processed_images:
        pair_images_and_concat(processed_images, paired_dir, concat_axis=1)
        # 4. å¯è§†åŒ–ç¤ºä¾‹ï¼ˆå±•ç¤ºåŸå§‹ä¸å¤„ç†åçš„å›¾åƒå¯¹æ¯”ï¼‰
        sample_img = cv2.imread(processed_images[0])
        sample_img_rgb = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)
        plt.figure(figsize=(6, 6))
        plt.imshow(sample_img_rgb)
        plt.title("Processed Image Sample")
        plt.axis("off")
        plt.show()
    else:
        print("å¤„ç†åçš„å›¾åƒåˆ—è¡¨ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶å¤¹å’Œæ–‡ä»¶æ‰©å±•åã€‚")
